{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-07863a32ab00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenWeatherKey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "from config import openWeatherKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Disaster Subsubtype</th>\n",
       "      <th>Entry Criteria</th>\n",
       "      <th>ISO</th>\n",
       "      <th>Location</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>End Month</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>No Injured</th>\n",
       "      <th>No Affected</th>\n",
       "      <th>No Homeless</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Insured Damages ('000 US$)</th>\n",
       "      <th>Total Damages ('000 US$)</th>\n",
       "      <th>CPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-0080-USA</td>\n",
       "      <td>2000</td>\n",
       "      <td>80</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Riverine flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affect</td>\n",
       "      <td>USA</td>\n",
       "      <td>Kentucky, Ohio provinces</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.355759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-0500-USA</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Riverine flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affect</td>\n",
       "      <td>USA</td>\n",
       "      <td>Morris, Sussex districts (New Jersey province)</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166000.0</td>\n",
       "      <td>67.355759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-0919-USA</td>\n",
       "      <td>2000</td>\n",
       "      <td>919</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SigDam</td>\n",
       "      <td>USA</td>\n",
       "      <td>Alabama, Georgia, Louisiana, North Carolina, S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>67.355759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-9712-USA</td>\n",
       "      <td>2000</td>\n",
       "      <td>9712</td>\n",
       "      <td>Climatological</td>\n",
       "      <td>Drought</td>\n",
       "      <td>Drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affected</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wyoming province</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.355759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-0838-USA</td>\n",
       "      <td>2000</td>\n",
       "      <td>838</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Convective storm</td>\n",
       "      <td>Winter storm/Blizzard</td>\n",
       "      <td>Kill</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas, Oklahoma, New Mexico, Arkansas, Missour...</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>200500.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>67.355759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2019-0307-USA</td>\n",
       "      <td>2019</td>\n",
       "      <td>307</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affected</td>\n",
       "      <td>USA</td>\n",
       "      <td>Lincolnton region (Lincoln County, North Carol...</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2020-0148-USA</td>\n",
       "      <td>2020</td>\n",
       "      <td>148</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Convective storm</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>Kill</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana, Texas, Mississippi, South Carolina,...</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2020-0011-USA</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Convective storm</td>\n",
       "      <td>Severe storm</td>\n",
       "      <td>Kill</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas, Oklahoma, Missouri, Arkansas, Louisiana...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2020-0082-USA</td>\n",
       "      <td>2020</td>\n",
       "      <td>82</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Convective storm</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>Waiting</td>\n",
       "      <td>USA</td>\n",
       "      <td>Nashville (Tennessee), Kentucky, Missouri, Mis...</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2020-0219-USA</td>\n",
       "      <td>2020</td>\n",
       "      <td>219</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affected</td>\n",
       "      <td>USA</td>\n",
       "      <td>errebonne, Plaquemines, Lafourche Parishes (Lo...</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Dis No  Year   Seq Disaster Subgroup Disaster Type  \\\n",
       "2    2000-0080-USA  2000    80      Hydrological         Flood   \n",
       "3    2000-0500-USA  2000   500      Hydrological         Flood   \n",
       "4    2000-0919-USA  2000   919    Meteorological         Storm   \n",
       "5    2000-9712-USA  2000  9712    Climatological       Drought   \n",
       "6    2000-0838-USA  2000   838    Meteorological         Storm   \n",
       "..             ...   ...   ...               ...           ...   \n",
       "532  2019-0307-USA  2019   307      Hydrological         Flood   \n",
       "533  2020-0148-USA  2020   148    Meteorological         Storm   \n",
       "534  2020-0011-USA  2020    11    Meteorological         Storm   \n",
       "535  2020-0082-USA  2020    82    Meteorological         Storm   \n",
       "536  2020-0219-USA  2020   219    Meteorological         Storm   \n",
       "\n",
       "     Disaster Subtype    Disaster Subsubtype Entry Criteria  ISO  \\\n",
       "2      Riverine flood                    NaN         Affect  USA   \n",
       "3      Riverine flood                    NaN         Affect  USA   \n",
       "4                 NaN                    NaN         SigDam  USA   \n",
       "5             Drought                    NaN       Affected  USA   \n",
       "6    Convective storm  Winter storm/Blizzard           Kill  USA   \n",
       "..                ...                    ...            ...  ...   \n",
       "532               NaN                    NaN       Affected  USA   \n",
       "533  Convective storm                Tornado           Kill  USA   \n",
       "534  Convective storm           Severe storm           Kill  USA   \n",
       "535  Convective storm                Tornado        Waiting  USA   \n",
       "536  Tropical cyclone                    NaN       Affected  USA   \n",
       "\n",
       "                                              Location  Start Month  \\\n",
       "2                             Kentucky, Ohio provinces            2   \n",
       "3       Morris, Sussex districts (New Jersey province)            8   \n",
       "4    Alabama, Georgia, Louisiana, North Carolina, S...            1   \n",
       "5                                     Wyoming province           11   \n",
       "6    Texas, Oklahoma, New Mexico, Arkansas, Missour...           12   \n",
       "..                                                 ...          ...   \n",
       "532  Lincolnton region (Lincoln County, North Carol...            6   \n",
       "533  Louisiana, Texas, Mississippi, South Carolina,...            4   \n",
       "534  Texas, Oklahoma, Missouri, Arkansas, Louisiana...            1   \n",
       "535  Nashville (Tennessee), Kentucky, Missouri, Mis...            3   \n",
       "536  errebonne, Plaquemines, Lafourche Parishes (Lo...            6   \n",
       "\n",
       "     End Month  Total Deaths  No Injured  No Affected  No Homeless  \\\n",
       "2          2.0           3.0         NaN        231.0          NaN   \n",
       "3          8.0           NaN         NaN        175.0          NaN   \n",
       "4          1.0           4.0         NaN          NaN          NaN   \n",
       "5          NaN           NaN         NaN          NaN          NaN   \n",
       "6         12.0          57.0        34.0          NaN          NaN   \n",
       "..         ...           ...         ...          ...          ...   \n",
       "532        6.0           3.0         NaN        600.0          NaN   \n",
       "533        4.0          38.0       200.0          NaN          NaN   \n",
       "534        1.0          12.0         NaN          NaN          NaN   \n",
       "535        3.0          25.0       300.0      12000.0          NaN   \n",
       "536        6.0           1.0         NaN          NaN          NaN   \n",
       "\n",
       "     Total Affected  Insured Damages ('000 US$)  Total Damages ('000 US$)  \\\n",
       "2             231.0                         NaN                       NaN   \n",
       "3             175.0                         NaN                  166000.0   \n",
       "4               NaN                    280000.0                  350000.0   \n",
       "5               NaN                         NaN                       NaN   \n",
       "6              34.0                    200500.0                   10000.0   \n",
       "..              ...                         ...                       ...   \n",
       "532           600.0                         NaN                       NaN   \n",
       "533           200.0                         NaN                 1000000.0   \n",
       "534             NaN                         NaN                 1200000.0   \n",
       "535         12300.0                         NaN                 1100000.0   \n",
       "536             NaN                         NaN                  325000.0   \n",
       "\n",
       "            CPI  \n",
       "2     67.355759  \n",
       "3     67.355759  \n",
       "4     67.355759  \n",
       "5     67.355759  \n",
       "6     67.355759  \n",
       "..          ...  \n",
       "532  100.000000  \n",
       "533         NaN  \n",
       "534         NaN  \n",
       "535         NaN  \n",
       "536         NaN  \n",
       "\n",
       "[474 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pulling data from csv files and creating dataframe with disaster data\n",
    "coordinates_csv = \"output_data/NEW_coordinates.csv\"\n",
    "weatherDisasterCSV = \"Resources/disaster_data.csv\"\n",
    "wDisaster_df = pd.read_csv(weatherDisasterCSV)\n",
    "desiredColumns = [\"Dis No\", \"Year\", \"Seq\", \"Disaster Subgroup\", \"Disaster Type\", \"Disaster Subtype\", \"Disaster Subsubtype\", \"Entry Criteria\", \"ISO\", \"Location\", \"Start Month\", \"End Month\", \"Total Deaths\", \"No Injured\", \"No Affected\", \"No Homeless\", \"Total Affected\", \"Insured Damages ('000 US$)\", \"Total Damages ('000 US$)\", \"CPI\"]\n",
    "wDisaster_df = wDisaster_df.loc[wDisaster_df[\"ISO\"] == \"USA\", desiredColumns]\n",
    "wDisaster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breaksdown and counts all unique locations\n",
    "#wDisaster_df[\"Location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe by splitting data into Location and Dis. No.\n",
    "newData = {\n",
    "    \"Location\": [],\n",
    "    \"Dis No\": []\n",
    "}\n",
    "\n",
    "for index, row in wDisaster_df.iterrows():\n",
    "    #print(type(newData[\"Location\"]))\n",
    "    if type(row[\"Location\"]) is str:\n",
    "        for location in row[\"Location\"].split(\",\"):\n",
    "            newData[\"Location\"].append(location)\n",
    "            newData[\"Dis No\"].append(row[\"Dis No\"])\n",
    "splitLocations_df = pd.DataFrame(newData)\n",
    "#splitLocations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping disaster dataframe and counting based on disaster type\n",
    "#wDisaster_df.groupby(\"Disaster Type\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2000-0080-USA</td>\n",
       "      <td>34.61</td>\n",
       "      <td>-92.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morris</td>\n",
       "      <td>2000-0500-USA</td>\n",
       "      <td>40.83</td>\n",
       "      <td>-74.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2000-0919-USA</td>\n",
       "      <td>32.75</td>\n",
       "      <td>-86.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2000-0919-USA</td>\n",
       "      <td>32.75</td>\n",
       "      <td>-83.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2000-0919-USA</td>\n",
       "      <td>31.00</td>\n",
       "      <td>-92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2020-0082-USA</td>\n",
       "      <td>34.61</td>\n",
       "      <td>-92.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>2020-0082-USA</td>\n",
       "      <td>38.25</td>\n",
       "      <td>-92.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2020-0082-USA</td>\n",
       "      <td>32.75</td>\n",
       "      <td>-89.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2020-0082-USA</td>\n",
       "      <td>32.75</td>\n",
       "      <td>-83.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>Texas</td>\n",
       "      <td>2020-0082-USA</td>\n",
       "      <td>31.25</td>\n",
       "      <td>-99.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2861 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Location         Dis No    Lat   Long\n",
       "0        Kentucky  2000-0080-USA  34.61 -92.66\n",
       "1          Morris  2000-0500-USA  40.83 -74.53\n",
       "2         Alabama  2000-0919-USA  32.75 -86.75\n",
       "3         Georgia  2000-0919-USA  32.75 -83.50\n",
       "4       Louisiana  2000-0919-USA  31.00 -92.00\n",
       "...           ...            ...    ...    ...\n",
       "2856     Kentucky  2020-0082-USA  34.61 -92.66\n",
       "2857     Missouri  2020-0082-USA  38.25 -92.50\n",
       "2858  Mississippi  2020-0082-USA  32.75 -89.75\n",
       "2859      Georgia  2020-0082-USA  32.75 -83.50\n",
       "2860        Texas  2020-0082-USA  31.25 -99.25\n",
       "\n",
       "[2861 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading coordinates csv file and creating new dataframe\n",
    "coordinates_location_df = pd.read_csv(coordinates_csv)\n",
    "clean_coordinates_index = coordinates_location_df.index\n",
    "coordinates_location_df = coordinates_location_df.loc[:, [\"Location\", \"Dis No\", \"Lat\", \"Long\"]]\n",
    "coordinates_location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Northwest coordinates >40N, >110W, and Hawaii\n",
    "#I need to first create a dataframe based on Longitude, <-130W, >-110W\n",
    "fourth_quintant_df = coordinates_location_df.loc[(coordinates_location_df[\"Long\"] > -130) & (coordinates_location_df[\"Long\"] < -110), :]\n",
    "#Create dataframe based on Latitude conditions >40N\n",
    "fourth_quintant_n_df = fourth_quintant_df.loc[fourth_quintant_df[\"Lat\"] > 40, :].reset_index(drop=True)\n",
    "#Create dataframe based on Latitude conditions <50N\n",
    "fourth_quintant_s_df = fourth_quintant_df.loc[fourth_quintant_df[\"Lat\"] < 50, :].reset_index(drop=True)\n",
    "#Create dataframes based on unique locations within the set conditions for the NW\n",
    "affected_area_n_df = len(fourth_quintant_n_df[\"Location\"].unique())\n",
    "affected_area_s_df = len(fourth_quintant_s_df[\"Location\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affected_area_n_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#affected_area_s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_x</th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Lat_x</th>\n",
       "      <th>Long_x</th>\n",
       "      <th>Location_y</th>\n",
       "      <th>Lat_y</th>\n",
       "      <th>Long_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richland</td>\n",
       "      <td>2000-0338-USA</td>\n",
       "      <td>46.29</td>\n",
       "      <td>-119.28</td>\n",
       "      <td>Richland</td>\n",
       "      <td>46.29</td>\n",
       "      <td>-119.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2000-0465-USA</td>\n",
       "      <td>44.50</td>\n",
       "      <td>-114.25</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>34.50</td>\n",
       "      <td>-111.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2000-0465-USA</td>\n",
       "      <td>44.50</td>\n",
       "      <td>-114.25</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>44.50</td>\n",
       "      <td>-114.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2000-0465-USA</td>\n",
       "      <td>44.50</td>\n",
       "      <td>-114.25</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>39.25</td>\n",
       "      <td>-116.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2000-0465-USA</td>\n",
       "      <td>44.50</td>\n",
       "      <td>-114.25</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>44.00</td>\n",
       "      <td>-120.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-0468-USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hidden Hills</td>\n",
       "      <td>34.16</td>\n",
       "      <td>-118.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-0086-USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>38.29</td>\n",
       "      <td>-122.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-0517-USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-0517-USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>34.11</td>\n",
       "      <td>-117.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-0517-USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>34.28</td>\n",
       "      <td>-119.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Location_x         Dis No  Lat_x  Long_x      Location_y  Lat_y  Long_y\n",
       "0     Richland  2000-0338-USA  46.29 -119.28        Richland  46.29 -119.28\n",
       "1        Idaho  2000-0465-USA  44.50 -114.25         Arizona  34.50 -111.50\n",
       "2        Idaho  2000-0465-USA  44.50 -114.25           Idaho  44.50 -114.25\n",
       "3        Idaho  2000-0465-USA  44.50 -114.25          Nevada  39.25 -116.75\n",
       "4        Idaho  2000-0465-USA  44.50 -114.25          Oregon  44.00 -120.50\n",
       "..         ...            ...    ...     ...             ...    ...     ...\n",
       "271        NaN  2018-0468-USA    NaN     NaN    Hidden Hills  34.16 -118.65\n",
       "272        NaN  2019-0086-USA    NaN     NaN          Sonoma  38.29 -122.46\n",
       "273        NaN  2019-0517-USA    NaN     NaN     Los Angeles  34.05 -118.24\n",
       "274        NaN  2019-0517-USA    NaN     NaN  San Bernardino  34.11 -117.29\n",
       "275        NaN  2019-0517-USA    NaN     NaN         Ventura  34.28 -119.29\n",
       "\n",
       "[276 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I need to merge lat dataframes along Location\n",
    "combined_quintant_lat_df = pd.merge(fourth_quintant_n_df, fourth_quintant_s_df, on = \"Dis No\", how=\"outer\")\n",
    "combined_quintant_lat_df\n",
    "#I need to merge long dataframe with new combined lat dataframe\n",
    "# combined_quintant_nw_df = pd.merge(combined_quintant_lat_df, fourth_quintant_df, on = \"Location\", how=\"inner\")\n",
    "# combined_quintant_nw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #I need to create a new dataframe combining the new combine quintant coordinates and the weather disaster data\n",
    "# combined_data_nw_df = pd.merge(combined_quintant_nw_df, wDisaster_df, on = \"Dis No\", how=\"outer\")\n",
    "# combined_data_nw_df\n",
    "# #I need to recreate dataframe by dropping all NaN values\n",
    "# combined_data_nw_df.replace({'Location_x': 'NaN'}, {'Location_x': float('NaN')})\n",
    "# combined_data_nw_df.replace({'Total Deaths': 'NaN'}, {'Total Deaths': float('NaN')})\n",
    "# combined_data_nw_df.replace({'Total Injured': 'NaN'}, {'No Injured': float('NaN')})\n",
    "# clean_combined_nw_df = combined_data_nw_df.dropna(subset=[\"Location_x\", \"Total Deaths\", \"No Injured\"])\n",
    "# clean_combined_nw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_combined_nw_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d9d0ddff3ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Combine \"Location_x\" and rename \"Location\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgroup_nw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_combined_nw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Location_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Lat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Long\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgroup_nw_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_combined_nw_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Combine \"Location_x\" and rename \"Location\"\n",
    "group_nw_df = clean_combined_nw_df.groupby([\"Location_x\", \"Lat\", \"Long\"]).agg\n",
    "group_nw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to clean up dataframe where the Location column has no information\n",
    "#clean_ = combined_data_nw_df.iloc[:,0]\n",
    "# clean_loc.dropna()\n",
    "# clean_loc\n",
    "# clean_data_nw_loc_df = pd.merge(combined_data_nw_df, clean_loc)\n",
    "# clean_data_nw_loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-8b575f9a0d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0munique_quintant_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_dis_nw_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique_dis_nw_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Lat\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0munique_quintant_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0munique_affected_area_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_quintant_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Location_x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0munique_affected_area_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_quintant_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Location_x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0munique_affected_area_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "#Creating a trimmed DF of dropped duplicates for more accurate calculations\n",
    "unique_dis_nw_df = clean_combined_nw_df.drop_duplicates(subset=\"Dis No\", keep=\"first\")\n",
    "#unique_dis_nw_df\n",
    "unique_quintant_n = unique_dis_nw_df.loc[unique_dis_nw_df[\"Lat\"] > 40, :].reset_index(drop=True)\n",
    "#unique_quintant_n\n",
    "unique_quintant_s = unique_dis_nw_df.loc[unique_dis_nw_df[\"Lat\"] < 50, :].reset_index(drop=True)\n",
    "unique_quintant_s\n",
    "unique_affected_area_n = len(unique_quintant_n[\"Location_x\"].unique())\n",
    "unique_affected_area_s = len(unique_quintant_s[\"Location_x\"].unique())\n",
    "unique_affected_area_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth_quintant = combined_data_df.loc[(coordinates_location_df[\"Long\"] < -90) & (combined_data_df[\"Long\"] > -110), :]\n",
    "# fourth_quintant_n = fourth_quintant.loc[fourth_quintant[\"Lat\"] > 40, :].reset_index(drop=True)\n",
    "# fourth_quintant_s = fourth_quintant.loc[fourth_quintant[\"Lat\"] < 40, :].reset_index(drop=True)\n",
    "# affected_area_n = len(fourth_quintant_n[\"Location_x\"].unique())\n",
    "# affected_area_s = len(fourth_quintant_s[\"Location_x\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Storm', 'Wildfire', 'Flood', 'Extreme temperature', 'Drought',\n",
       "       'Earthquake', 'Epidemic', 'Landslide', 'Volcanic activity'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create df with dropped duplicates types\n",
    "#dis_no_unique_df = fourth_quintant\n",
    "disaster_type = combined_data_nw_df[\"Disaster Type\"].unique()\n",
    "# disaster_type_count_n = fourth_quintant_n[\"Disaster Type\"].value_counts()\n",
    "# disaster_type_count_s = fourth_quintant_s[\"Disaster Type\"].value_counts()\n",
    "disaster_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fourth_quintant_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1ca3e21766f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfourth_quintant_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfourth_quintant_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Disaster Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Storm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fourth_quintant_n' is not defined"
     ]
    }
   ],
   "source": [
    "fourth_quintant_n.loc[fourth_quintant_n[\"Disaster Type\"] == \"Storm\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinates_location_df[\"Location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates_data = {\n",
    "#     \"Location\": [],\n",
    "#     \"Dis No\": [],\n",
    "#     \"Lat\": [],\n",
    "#     \"Long\": []\n",
    "# }\n",
    "\n",
    "# for index, row in coordinates_location_df.iterrows():\n",
    "#     #print(type(coordinates_data[\"Location\"]))\n",
    "#     if type(row[\"Location\"]) is str:\n",
    "#         for location in row[\"Location\"].split(\",\"):\n",
    "#             newData[\"Location\"].append(location)\n",
    "#             newData[\"Dis No\"].append(row[\"Dis No\"])\n",
    "# split_coordinates_df = pd.DataFrame(coordinates_data)\n",
    "# split_coordinates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-59-3abbedc0f56d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-59-3abbedc0f56d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    fourth_quintant = coordinates_location_df.loc[coordinates_location_df[\"Long\"] < -90) & (coordinates_location_df[\"Long\"] > -110), :]\u001b[0m\n\u001b[0m                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
